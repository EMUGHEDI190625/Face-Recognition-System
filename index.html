<!-- <!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ECN Face Recognition System</title>

<script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<style>
body{
  text-align:center;
  font-family:Arial;
  background:#f4f4f4;
}
video{
  border:3px solid black;
  border-radius:10px;
}
canvas{
  position:absolute;
}
#container{
  position:relative;
  display:inline-block;
}
button{
  padding:12px 20px;
  margin-top:15px;
  font-size:18px;
  cursor:pointer;
}
</style>
</head>

<body>

<h2>ECN Face Capture</h2>

<div id="container">
  <video id="video" width="350" height="260" autoplay muted></video>
</div>

<br>
<button onclick="captureFace()">Capture Face</button>

<p id="status"></p>

<script>

const video = document.getElementById("video");

async function startCamera(){
 const stream = await navigator.mediaDevices.getUserMedia({ video:true });
 video.srcObject = stream;
}
startCamera();


async function loadModels(){
 document.getElementById("status").innerText="Loading AI models...";
 await faceapi.nets.ssdMobilenetv1.loadFromUri("models");
 await faceapi.nets.faceLandmark68Net.loadFromUri("models");
 await faceapi.nets.faceRecognitionNet.loadFromUri("models");
 document.getElementById("status").innerText="Models Loaded ✅";
}
loadModels();



video.addEventListener("play", ()=>{
 const canvas = faceapi.createCanvasFromMedia(video);
 document.getElementById("container").append(canvas);

 const size = {
  width: video.width,
  height: video.height
 };

 faceapi.matchDimensions(canvas,size);

 setInterval(async()=>{
   const detections = await faceapi
   .detectAllFaces(video)
   .withFaceLandmarks()
   .withFaceDescriptors();

   const resized = faceapi.resizeResults(detections,size);

   canvas.getContext("2d").clearRect(0,0,canvas.width,canvas.height);

   faceapi.draw.drawDetections(canvas,resized);
   faceapi.draw.drawFaceLandmarks(canvas,resized);

 },100);
});



async function captureFace(){

 const detection = await faceapi
 .detectSingleFace(video)
 .withFaceLandmarks()
 .withFaceDescriptor();

 if(!detection){
   alert("No face detected!");
   return;
 }

 const descriptor = detection.descriptor;

 console.log("Face Descriptor:",descriptor);

 document.getElementById("status").innerText=
 "Face captured successfully ✅";

}
</script>

</body>
</html>
 -->


<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ECN Face Recognition System</title>

<script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<style>
body{
  text-align:center;
  font-family:Arial;
  background:#f4f4f4;
}
video{
  border:3px solid black;
  border-radius:10px;
}
canvas{
  position:absolute;
  left:0;
  top:0;
}
#container{
  position:relative;
  display:inline-block;
}
button{
  padding:12px 20px;
  margin-top:15px;
  font-size:18px;
  cursor:pointer;
}
</style>
</head>

<body>

<h2>ECN Face Capture</h2>

<div id="container">
<video id="video" width="350" height="260" autoplay muted playsinline></video>
</div>

<br>
<button id="captureBtn">Capture Face</button>

<p id="status">Initializing...</p>

<script>

const video = document.getElementById("video")
const statusText = document.getElementById("status")
const captureBtn = document.getElementById("captureBtn")

// ================= CAMERA =================
async function startCamera(){

 try{
  const stream = await navigator.mediaDevices.getUserMedia({
   video:{ facingMode:"user" },
   audio:false
  })

  video.srcObject = stream

 }catch(err){
  statusText.innerText = "Camera access denied ❌"
  alert(err)
 }

}

// ================= LOAD MODELS =================
async function loadModels(){

 statusText.innerText="Loading AI models..."

 await faceapi.nets.ssdMobilenetv1.loadFromUri("models")
 await faceapi.nets.faceLandmark68Net.loadFromUri("models")
 await faceapi.nets.faceRecognitionNet.loadFromUri("models")

 statusText.innerText="Models Loaded ✅"
 captureBtn.disabled=false

}

// ================= START EVERYTHING =================
async function init(){
 await startCamera()
 await loadModels()
}
init()



// ================= FACE DETECTION LOOP =================
video.addEventListener("play",()=>{

 const canvas = faceapi.createCanvasFromMedia(video)
 document.getElementById("container").append(canvas)

 const size = {
  width:video.width,
  height:video.height
 }

 faceapi.matchDimensions(canvas,size)

 setInterval(async()=>{

  const detections = await faceapi
  .detectAllFaces(video)
  .withFaceLandmarks()
  .withFaceDescriptors()

  const resized = faceapi.resizeResults(detections,size)

  canvas.getContext("2d").clearRect(0,0,canvas.width,canvas.height)

  faceapi.draw.drawDetections(canvas,resized)
  faceapi.draw.drawFaceLandmarks(canvas,resized)

 },150)

})



// ================= CAPTURE FUNCTION =================
captureBtn.addEventListener("click", async ()=>{

 statusText.innerText="Capturing..."

 const detection = await faceapi
 .detectSingleFace(video)
 .withFaceLandmarks()
 .withFaceDescriptor()

 if(!detection){
  statusText.innerText="No face detected ❌"
  return
 }

 console.log("Descriptor:", detection.descriptor)

 statusText.innerText="Face captured successfully ✅"

})

</script>
</body>
</html>

